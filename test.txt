import requests
import time
from bs4 import BeautifulSoup

siren_list = ['SIREN1', 'SIREN2', 'SIREN3']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
    # Add other headers if needed
}

for siren in siren_list:
    url = f'https://www.pappers.fr/entreprise?{siren}'
    time.sleep(5)  # Be polite and wait between requests
    response = requests.get(url, headers=headers)
    
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        # Your scraping logic here
    else:
        print(f"Failed to retrieve data for SIREN: {siren}. Status code: {response.status_code}")
